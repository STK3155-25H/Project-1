% File: ols_mse.tex
\begin{figure}[H]
\begin{tikzpicture}
\begin{axis}[
    width=8cm,
    height=6cm,
    xlabel={Polynomial degree},
    ylabel={MSE},
    title={RIDGE Regression With Advanced SGD Methods},
    legend pos=north east,
    grid=both,
    y tick label style={
        /pgf/number format/fixed,
        /pgf/number format/precision=2
    },
    ]
    \addplot [blue, mark=none] table [x=degree, col sep=comma] {../outputs/tables/part_f_ridge_mse_vanilla_lr=0.01_sgd.csv};
    \addlegendentry{$vanilla$}

    \addplot [orange, mark=none] table [x=degree, col sep=comma] {../outputs/tables/part_f_ridge_mse_momentum_lr=0.01_sgd.csv};
    \addlegendentry{$momentum$}

    \addplot [green!60!black, mark=none] table [x=degree, col sep=comma] {../outputs/tables/part_f_ridge_mse_adagrad_lr=0.01_sgd.csv};
    \addlegendentry{$adagrad$}

    \addplot [red, mark=none] table [x=degree, col sep=comma] {../outputs/tables/part_f_ridge_mse_rmsprop_lr=0.01_sgd.csv};
    \addlegendentry{$rmsprop$}

    \addplot [purple, mark=none] table [x=degree, col sep=comma] {../outputs/tables/part_f_ridge_mse_adam_lr=0.01_sgd.csv};
    \addlegendentry{$adam$}
\end{axis}
\end{tikzpicture}
\caption{Comparison of Ridge regression test MSE using analytical and stachastic-gradient-based methods. The plot shows mean squared error across polynomial degrees for the analytical solution, vanilla gradient descent, momentum, Adagrad, RMSProp, and Adam ($learning rate = 0.01$), highlighting differences in convergence and generalization performance between exact and iterative approaches.}
\label{fig:AGD_RIDGE_SGD}
\end{figure}
